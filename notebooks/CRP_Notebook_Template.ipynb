{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Template Notebook"
      ],
      "metadata": {
        "id": "ye9E-yefldQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration"
      ],
      "metadata": {
        "id": "XlwCbPPKlNCG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fe3LUcwQjgWG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import zipfile\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set globals\n",
        "USER = 'josemarquezjaramillo'\n",
        "REPO = 'crypto-rl-portfolio'\n",
        "DATASET = 'dataset_v1'"
      ],
      "metadata": {
        "id": "e166hNtxkJNo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pull repo - colab starts uninitialized\n",
        "os.system(f'git clone https://github.com/{USER}/{REPO}')\n",
        "os.chdir(REPO)\n",
        "\n",
        "# install requirements\n",
        "req_result = subprocess.run('pip install -r requirements-data.txt', shell=True, capture_output=True, text=True)\n",
        "\n",
        "print(\"=== STDOUT ===\")\n",
        "print(req_result.stdout.strip())   # remove extra blank lines\n",
        "print(\"\\n=== STDERR ===\")\n",
        "print(req_result.stderr.strip())\n",
        "\n",
        "print(f\"\\nExit code: {req_result.returncode}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WVAYWKMjnJ1",
        "outputId": "72addf01-4039-4b73-f6a3-7bf42abe1e94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STDOUT ===\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-data.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-data.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: sqlalchemy>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-data.txt (line 4)) (2.0.44)\n",
            "Collecting psycopg2-binary>=2.9.0 (from -r requirements-data.txt (line 5))\n",
            "  Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-data.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: pytest>=7.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements-data.txt (line 15)) (8.4.2)\n",
            "Collecting pytest-cov>=4.1.0 (from -r requirements-data.txt (line 16))\n",
            "  Downloading pytest_cov-7.0.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from -r requirements-data.txt (line 17)) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements-data.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements-data.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements-data.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=2.0.0->-r requirements-data.txt (line 4)) (3.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=2.0.0->-r requirements-data.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.4.0->-r requirements-data.txt (line 15)) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.4.0->-r requirements-data.txt (line 15)) (25.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.4.0->-r requirements-data.txt (line 15)) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.4.0->-r requirements-data.txt (line 15)) (2.19.2)\n",
            "Collecting coverage>=7.10.6 (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->-r requirements-data.txt (line 16))\n",
            "  Downloading coverage-7.11.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements-data.txt (line 2)) (1.17.0)\n",
            "Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 120.5 MB/s eta 0:00:00\n",
            "Downloading pytest_cov-7.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading coverage-7.11.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (250 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250.6/250.6 kB 26.5 MB/s eta 0:00:00\n",
            "Installing collected packages: psycopg2-binary, coverage, pytest-cov\n",
            "Successfully installed coverage-7.11.0 psycopg2-binary-2.9.11 pytest-cov-7.0.0\n",
            "\n",
            "=== STDERR ===\n",
            "\n",
            "\n",
            "Exit code: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract data\n",
        "with zipfile.ZipFile(f\"data/{DATASET}.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")"
      ],
      "metadata": {
        "id": "vpWbLaZ4uq2P"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "aeZr039ouvqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(os.getcwd())"
      ],
      "metadata": {
        "id": "bQTaot-c4bto"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# local imports\n",
        "from agents import *\n",
        "from environment import *\n",
        "from tests import *\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "# get cuda\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGhp345ua1T",
        "outputId": "340da124-d953-40a4-ced4-62adfea53425"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Read Data"
      ],
      "metadata": {
        "id": "WIMSwULeoD9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_asset_lists(subset):\n",
        "    data = []\n",
        "    with open(f\"{DATASET}/{subset}_asset_lists.jsonl\") as f:\n",
        "        for line in f:\n",
        "            json_object = json.loads(line.strip())\n",
        "            data.append(json_object)\n",
        "    return data\n",
        "\n",
        "def read_index(subset):\n",
        "  return pd.read_parquet(f\"{DATASET}/{subset}_index.parquet\")\n",
        "\n",
        "def read_fwd_returns(subset):\n",
        "  return np.load(f\"{DATASET}/{subset}_fwd_returns.npz\")\n",
        "\n",
        "def read_obs_tensors(subset):\n",
        "  return np.load(f\"{DATASET}/{subset}_obs_tensors.npz\")\n",
        "\n",
        "metadata = json.load(open(f\"{DATASET}/metadata.json\"))\n",
        "dev_asset_list = read_asset_lists('dev')\n",
        "dev_index = read_index('dev')\n",
        "dev_tensors = read_obs_tensors('dev')"
      ],
      "metadata": {
        "id": "nbZj5WgZlBtS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_obs(idx_tbl, tensors, idx):\n",
        "  date = idx_tbl['date'][idx].strftime('t_%Y-%m-%d')\n",
        "  return tensors[date]"
      ],
      "metadata": {
        "id": "219Z3Q3dtF_Q"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_obs(dev_index, dev_tensors, 0)"
      ],
      "metadata": {
        "id": "NID02OqYsn9i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoKhodTCrfMl",
        "outputId": "e988922f-ae4b-4818-c9ab-11b9bdefd7e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 4, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Example Code (Environment)"
      ],
      "metadata": {
        "id": "ktpyNUfI55oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m environment.environment_smoke_run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UduRxO_ftyfb",
        "outputId": "81879880-c16b-43e8-bfa4-0819ed02205e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "SMOKE TEST: PortfolioEnv End-to-End Demonstration\n",
            "================================================================================\n",
            "\n",
            "[1/6] Loading dataset artifacts...\n",
            "  ✓ Loaded 960 days from dataset_v1/dev\n",
            "\n",
            "[2/6] Creating data backends...\n",
            "  ✓ Training backend: 922 days\n",
            "  ✓ Validation backend: 38 days (2 windows)\n",
            "\n",
            "[3/6] Initializing environments...\n",
            "  ✓ Training env: 65 days\n",
            "  ✓ Validation env: 19 days\n",
            "\n",
            "[4/6] Initializing agents...\n",
            "  ✓ Random agent (exponential weights)\n",
            "  ✓ Uniform agent (1/N baseline)\n",
            "\n",
            "[5/6] Training agents...\n",
            "\n",
            "  Random Agent (Training):\n",
            "  Episode 1/3... PV=0.8887, reward=-0.1180\n",
            "  Episode 2/3... PV=1.0048, reward=0.0048\n",
            "  Episode 3/3... PV=0.8382, reward=-0.1765\n",
            "\n",
            "  Uniform Agent (Training):\n",
            "  Episode 1/3... PV=0.8922, reward=-0.1141\n",
            "  Episode 2/3... PV=0.8922, reward=-0.1141\n",
            "  Episode 3/3... PV=0.8922, reward=-0.1141\n",
            "\n",
            "[6/6] Evaluating on validation set...\n",
            "\n",
            "  Random Agent (Validation):\n",
            "  Episode 1/1... PV=0.6873, reward=-0.3749\n",
            "\n",
            "  Uniform Agent (Validation):\n",
            "  Episode 1/1... PV=0.6729, reward=-0.3961\n",
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Training Performance (5 months, 3 episodes):\n",
            "------------------------------------------------------------\n",
            "Agent                Mean PV       Std PV     Mean Reward\n",
            "------------------------------------------------------------\n",
            "Random                0.9106       0.0698         -0.0966\n",
            "Uniform               0.8922       0.0000         -0.1141\n",
            "\n",
            "Validation Performance (all windows, 1 episode):\n",
            "------------------------------------------------------------\n",
            "Agent                Mean PV     Mean Reward\n",
            "------------------------------------------------------------\n",
            "Random                0.6873         -0.3749\n",
            "Uniform               0.6729         -0.3961\n",
            "\n",
            "================================================================================\n",
            "OBSERVATIONS\n",
            "================================================================================\n",
            "\n",
            "1. Environment Integration\n",
            "   - Dataset loading: ✓ Working\n",
            "   - Backend adapter: ✓ Working  \n",
            "   - Environment initialization: ✓ Working\n",
            "   - Episode execution: ✓ Working\n",
            "\n",
            "2. Constraint Enforcement\n",
            "   - Portfolio values always positive (no negative wealth)\n",
            "   - Turnover capped at configured level\n",
            "   - Costs proportional to turnover\n",
            "   - Episodes terminate cleanly\n",
            "\n",
            "3. Ready for RL Training\n",
            "   - State representation consistent [A_t, 4, 60]\n",
            "   - Actions projected to feasible set\n",
            "   - Rewards computed with transaction costs\n",
            "   - Deterministic with seeding\n",
            "\n",
            "NEXT STEPS:\n",
            "- Implement A2C/PPO agent with policy network\n",
            "- Implement DQN agent with discrete action space\n",
            "- Tune hyperparameters on training set\n",
            "- Evaluate on held-out test split (2024-2025)\n",
            "- Compare against 1/N and momentum baselines\n",
            "    \n",
            "================================================================================\n",
            "✓ Smoke test completed successfully!\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ADDITIONAL USAGE EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 1: Continuous Action Space (Policy Gradient)\n",
            "================================================================================\n",
            "\n",
            "Initial observation:\n",
            "  - Features shape: (10, 4, 60)\n",
            "  - Assets: 10\n",
            "  - Date: 2018-09-01\n",
            "\n",
            "Step 1:\n",
            "  - Action (first 3): [0.02088974 0.40591934 0.03769317]\n",
            "  - Reward: 0.104348\n",
            "  - Turnover: 0.3000\n",
            "  - PV: 1.1100\n",
            "\n",
            "Step 2:\n",
            "  - Action (first 3): [0.18624927 0.00897378 0.06332076]\n",
            "  - Reward: -0.028157\n",
            "  - Turnover: 0.3000\n",
            "  - PV: 1.0792\n",
            "\n",
            "Step 3:\n",
            "  - Action (first 3): [0.0448502  0.02370842 0.03976509]\n",
            "  - Reward: 0.011776\n",
            "  - Turnover: 0.3000\n",
            "  - PV: 1.0920\n",
            "\n",
            "Step 4:\n",
            "  - Action (first 3): [0.2974263  0.02773275 0.05490088]\n",
            "  - Reward: 0.014506\n",
            "  - Turnover: 0.3000\n",
            "  - PV: 1.1079\n",
            "\n",
            "Step 5:\n",
            "  - Action (first 3): [0.0224103  0.02117818 0.0154629 ]\n",
            "  - Reward: -0.146704\n",
            "  - Turnover: 0.3000\n",
            "  - PV: 0.9567\n",
            "\n",
            "✓ Continuous action example complete\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 2: Discrete Action Space (DQN)\n",
            "================================================================================\n",
            "\n",
            "Action catalog size: 3\n",
            "Initial state: 10 assets\n",
            "\n",
            "Step 1:\n",
            "  - Action: balanced\n",
            "  - Q-values: [-0.11782497  0.23761875  0.45831131]\n",
            "  - Reward: 0.086614\n",
            "  - PV: 1.0905\n",
            "\n",
            "Step 2:\n",
            "  - Action: concentrated\n",
            "  - Q-values: [-0.63093621  0.62014824 -0.30524458]\n",
            "  - Reward: -0.018857\n",
            "  - PV: 1.0701\n",
            "\n",
            "Step 3:\n",
            "  - Action: balanced\n",
            "  - Q-values: [-1.20099759 -0.82507311  0.55193599]\n",
            "  - Reward: 0.005972\n",
            "  - PV: 1.0765\n",
            "\n",
            "Step 4:\n",
            "  - Action: concentrated\n",
            "  - Q-values: [-0.51701496  0.20779153 -0.4508732 ]\n",
            "  - Reward: 0.015966\n",
            "  - PV: 1.0938\n",
            "\n",
            "Step 5:\n",
            "  - Action: uniform\n",
            "  - Q-values: [ 2.13643597 -0.96563955  1.6381828 ]\n",
            "  - Reward: -0.122922\n",
            "  - PV: 0.9673\n",
            "\n",
            "✓ Discrete action example complete\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 3: CSV Logging\n",
            "================================================================================\n",
            "\n",
            "Log file created: env_train_789_20251104_172555.csv\n",
            "\n",
            "First 5 rows:\n",
            "  step,date,n_assets,turnover,transaction_cost,gross_log_return,reward_net,portfolio_value,constraint_nonneg,constraint_simplex,constraint_cap,constraint_turnover\n",
            "  1,2018-09-02,10,0.000000,0.000000,0.087993,0.087993,1.091981,0,1,0,0\n",
            "  2,2018-09-03,10,0.000000,0.000000,-0.029710,-0.029710,1.060015,0,1,0,0\n",
            "  3,2018-09-04,10,0.000000,0.000000,0.013420,0.013420,1.074336,0,1,0,0\n",
            "  4,2018-09-05,10,0.000000,0.000000,0.016860,0.016860,1.092603,0,1,0,0\n",
            "\n",
            "✓ Logging example complete\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 4: Action Mask for Batching\n",
            "================================================================================\n",
            "\n",
            "Observation keys: ['features', 'prev_weights', 'asset_ids', 'date', 'action_mask']\n",
            "Action mask shape: (50,)\n",
            "Action mask dtype: bool\n",
            "Valid assets (A_t): 10\n",
            "\n",
            "Step 1:\n",
            "  - Date: 2018-09-02\n",
            "  - Valid assets: 10\n",
            "  - Mask (first 12): [ True  True  True  True  True  True  True  True  True  True False False]\n",
            "\n",
            "Step 2:\n",
            "  - Date: 2018-09-03\n",
            "  - Valid assets: 10\n",
            "  - Mask (first 12): [ True  True  True  True  True  True  True  True  True  True False False]\n",
            "\n",
            "Step 3:\n",
            "  - Date: 2018-09-04\n",
            "  - Valid assets: 10\n",
            "  - Mask (first 12): [ True  True  True  True  True  True  True  True  True  True False False]\n",
            "\n",
            "✓ Action mask example complete\n",
            "\n",
            "================================================================================\n",
            "All examples completed!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}